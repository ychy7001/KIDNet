__include__: [
  '../dfine/dfine_hgnetv2_s_custom.yml',
  '../base/deim.yml'
]

print_freq: 20
output_dir: ./outputs/deim_hgnetv2_s_custom

DEIM:
  encoder: HybridEncoder_C2f_APB
  backbone: HGNetv2_MANet_Star_Block
  
HybridEncoder_C2f_APB:
  in_channels: [256, 512, 1024]
  feat_strides: [8, 16, 32]
  
  # intra
  hidden_dim: 256
  use_encoder_idx: [2]
  dim_feedforward: 1024

  # cross
  expansion: 0.34
  depth_mult: 0.5

HGNetv2_MANet_Star_Block:
  name: 'B0'
  return_idx: [1, 2, 3]
  freeze_at: -1
  freeze_norm: False
  use_lab: True
  pretrained: False

optimizer:
  type: AdamW
  params: 
    - 
      params: '^(?=.*backbone)(?!.*bn).*$'
      lr: 0.0002
    - 
      params: '^(?=.*(?:norm|bn)).*$'     # except bias
      weight_decay: 0.

  lr: 0.0004
  betas: [0.9, 0.999]
  weight_decay: 0.0001


# Increase to search for the optimal ema
epoches: 132 # 120 + 4n

## Our LR-Scheduler
flat_epoch: 64    # 4 + epoch // 2, e.g., 40 = 4 + 72 / 2
no_aug_epoch: 12

## Our DataAug
train_dataloader: 
  dataset: 
    transforms:
      policy:
        epoch: [4, 64, 120]   # list 

  collate_fn:
    mixup_epochs: [4, 64]
    stop_epoch: 120
  total_batch_size: 4
val_dataloader:
  total_batch_size: 4