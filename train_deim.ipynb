{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Block Index\n\n",
    "- [training](#training)\n",
    "- [train_setting](#train_setting)\n",
    "- [keep_best_runs](#keep_best_runs)\n",
    "- [map_sort](#map_sort)\n",
    "- [config_test_examination](#config_test_examination)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"training\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training\n",
    "!source /chenyan123/venvs/yolo/bin/activate\n",
    "%cd /chenyan123/models/det-sota/deim\n",
    "\n",
    "!export CUDA_VISIBLE_DEVICES=1\n",
    "!export MASTER_PORT=57003\n",
    "!torchrun --nproc_per_node=1 functions/train.py -c myConfigs/breast_bm_b-mode_deim_hgnetv2_n.yml --seed=0\n",
    "\n",
    "# test\n",
    "!torchrun --nproc_per_node=1 functions/train.py -c myConfigs/breast_bm_b-mode_deim_hgnetv2_s_custom.yml --test-only -r runs/breast_bm_b-mode/deim_hgnetv2_s_custom/726/best_stg2.pth\n",
    "!python tools/benchmark/get_info.py -c myConfigs/breast_bm_b-mode_deim_hgnetv2_s_custom.yml\n",
    "\n",
    "# clear\n",
    "!find /chenyan123/models/yolo/yolov12/ -type d -name \".ipynb_checkpoints\" -print0 | xargs -0 rm -rf\n",
    "!ps -ef | grep python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"train_setting\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_setting\n",
    "import os\n",
    "import csv\n",
    "# 文件路径\n",
    "csv_path = \"./yolov12/configs/breast_bm_b-mode_train.csv\"\n",
    "exclusion_path = \"./yolov12/configs/exclusion.csv\"\n",
    "# 指定单一数据集 (如果为 None, 则查找所有数据集)\n",
    "specified_dataset = \"breast_bm_b-mode\"  # 或者 None\n",
    "# 模型配置文件目录\n",
    "model_config_dir = \"./yolov12/ultralytics/cfg/models/11\"\n",
    "# 可选的排除旧模型目录，默认为 None\n",
    "# old_model_config_dir = \"./yolov12/ultralytics/cfg/models/11_old\"  \n",
    "old_model_config_dir = None\n",
    "\n",
    "# 数据集目录\n",
    "dataset_root = \"./datasets\"\n",
    "# 读取需要排除的模型\n",
    "excluded_models = set()\n",
    "if os.path.exists(exclusion_path):\n",
    "    with open(exclusion_path, mode=\"r\") as exclusion_file:\n",
    "        reader = csv.DictReader(exclusion_file)\n",
    "        for row in reader:\n",
    "            excluded_models.add(row[\"model\"])\n",
    "\n",
    "# Step 1: 查找数据集\n",
    "datasets = []\n",
    "if specified_dataset:\n",
    "    folder_path = os.path.join(dataset_root, specified_dataset)\n",
    "    if os.path.isdir(folder_path) and \"data.yaml\" in os.listdir(folder_path):\n",
    "        datasets.append(specified_dataset)\n",
    "    else:\n",
    "        print(f\"警告: 指定的数据集 '{specified_dataset}' 未找到或不包含 data.yaml 文件。\")\n",
    "else:\n",
    "    for folder in os.listdir(dataset_root):\n",
    "        folder_path = os.path.join(dataset_root, folder)\n",
    "        if os.path.isdir(folder_path) and \"data.yaml\" in os.listdir(folder_path):\n",
    "            datasets.append(folder)\n",
    "\n",
    "# Step 2: 查找模型配置文件\n",
    "models = []\n",
    "\n",
    "for file in os.listdir(model_config_dir):\n",
    "    if file.startswith(\"yolo11\") and file.endswith(\".yaml\"):\n",
    "        models.append(file)\n",
    "\n",
    "# 排除旧的模型目录中的模型\n",
    "if old_model_config_dir is not None and os.path.exists(old_model_config_dir):\n",
    "    old_models = set(file for file in os.listdir(old_model_config_dir) if file.startswith(\"yolo11\") and file.endswith(\".yaml\"))\n",
    "    excluded_models.update(old_models)  # 将旧模型添加到排除列表中\n",
    "\n",
    "\n",
    "# 过滤排除的模型\n",
    "models = [model for model in models if model not in excluded_models]\n",
    "\n",
    "# Step 3: 记录到 train.csv 文件\n",
    "with open(csv_path, mode=\"w\", newline=\"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    # 写入表头\n",
    "    writer.writerow([\"dataset\", \"model\"])\n",
    "\n",
    "    # 根据数据集和模型的数量，组合成行\n",
    "    max_len = max(len(datasets), len(models))\n",
    "    for i in range(max_len):\n",
    "        dataset = datasets[i] if i < len(datasets) else \"\"\n",
    "        model = models[i] if i < len(models) else \"\"\n",
    "        writer.writerow([dataset, model])\n",
    "\n",
    "print(f\"训练配置已保存至: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"keep_best_runs\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep_best_runs\n",
    "# 清理runs,整理总表,需要先运行batch_roc.py\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# --- 指定变量 ---\n",
    "dataset_name = \"thyroid_bm_b-mode\"\n",
    "metric_to_use = 'Weighted_metric'  #  在此处设置指标： 'F1-Score' 或 'Weighted_metric'\n",
    "METRIC_CHOICES = ['F1-Score', 'Weighted_metric'] #指标选项\n",
    "DEFAULT_METRIC = 'F1-Score'\n",
    "\n",
    "# --- 参数设置 ---\n",
    "runs_path = \"./yolov12/runs\"\n",
    "results_path = \"./yolov12/results\"\n",
    "overall_results_path = os.path.join(results_path, dataset_name, \"overall_results.csv\")\n",
    "train_log_path = os.path.join(results_path, dataset_name, \"train_log.csv\")\n",
    "best_metrics_path = os.path.join(results_path, dataset_name, \"best_patient_level_metrics.csv\") # 添加best_patient_level_metrics.csv路径\n",
    "max_subfolders_to_keep = 3  # 每个模型保留的最大子文件夹数量\n",
    "exp_prefix = \"exp\" # 定义待删除实验文件夹的前缀\n",
    "\n",
    "# --- 函数定义 ---\n",
    "\n",
    "def delete_model_and_results(model_name, subfolder_name, overall_df, train_log_df, train_log_path, overall_results_path):\n",
    "    \"\"\"删除模型训练结果和相关结果文件，并从CSV中删除记录 (四步骤删除).\"\"\"\n",
    "    model_run_path = os.path.join(runs_path, dataset_name, model_name, subfolder_name)\n",
    "    result_folder_path = os.path.join(results_path, dataset_name, model_name, subfolder_name)\n",
    "\n",
    "    print(f\"Deleting model: {model_name}/{subfolder_name}\")\n",
    "\n",
    "    # 1. 从 overall_df 中删除记录\n",
    "    overall_df = overall_df[~((overall_df['Model'] == model_name) & (overall_df['Subfolder'] == str(subfolder_name)))]\n",
    "    print(f\"Updated overall_df, removed entries for model: {model_name}, subfolder: {subfolder_name}\")\n",
    "\n",
    "    # 2. 从 train_log_df 中删除记录\n",
    "    train_log_df = train_log_df[~((train_log_df['model'].str.contains(model_name, na=False)) & (train_log_df['mAP'].str.contains(str(subfolder_name), na=False)))]\n",
    "    print(f\"Updated train_log_df, removed entries for model: {model_name}, subfolder: {subfolder_name}\")\n",
    "\n",
    "    # 3. 删除 results 目录下的结果文件夹\n",
    "    if os.path.exists(result_folder_path):\n",
    "        try:\n",
    "            shutil.rmtree(result_folder_path)\n",
    "            print(f\"Deleted results folder: {result_folder_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting results folder: {result_folder_path}. {e}\")\n",
    "\n",
    "    # 4. 删除 runs 目录下的模型文件夹\n",
    "    if os.path.exists(model_run_path):\n",
    "        try:\n",
    "            shutil.rmtree(model_run_path)\n",
    "            print(f\"Deleted runs folder: {model_run_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting runs folder: {model_run_path}. {e}\")\n",
    "\n",
    "    return overall_df, train_log_df\n",
    "\n",
    "\n",
    "def manage_models(overall_df, train_log_df, train_log_path, overall_results_path, best_metrics_df, metric_to_use):\n",
    "    \"\"\"管理模型，识别并删除性能较差的模型和多余的子文件夹.\"\"\"\n",
    "\n",
    "    models_to_delete = []  # 存储待删除的 (model_name, subfolder_name) 对\n",
    "    current_overall_df = overall_df.copy() # 使用 overall_df 的副本，避免循环中修改\n",
    "    current_train_log_df = train_log_df.copy() # 使用 train_log_df 的副本\n",
    "\n",
    "    # 强制转换 'Subfolder' 列为字符串类型\n",
    "    current_overall_df['Subfolder'] = current_overall_df['Subfolder'].astype(str)\n",
    "    print(f\"overall_df['Subfolder'] dtype after conversion: {current_overall_df['Subfolder'].dtype}\") # 打印转换后的数据类型\n",
    "\n",
    "    # 根据选择的指标确定列名\n",
    "    if metric_to_use == 'F1-Score':\n",
    "        best_metric_col = 'Best F1-Score'\n",
    "    elif metric_to_use == 'Weighted_metric':\n",
    "        best_metric_col = 'Weighted_metric'\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid metric: {metric_to_use}.  Must be one of {METRIC_CHOICES}\")\n",
    "\n",
    "    # 1. 删除性能较差的模型 (与之前的逻辑相同，但现在只是标记待删除)\n",
    "    for model_name in current_overall_df['Model'].unique(): # 循环 current_overall_df\n",
    "        # 获取当前模型的所有记录\n",
    "        overall_model_df = current_overall_df[current_overall_df['Model'] == model_name] # 使用 current_overall_df\n",
    "\n",
    "        # 在train_log_df中找到对应的mAP值 (注意这里改成了mAP)\n",
    "        train_log_model_df = current_train_log_df[current_train_log_df['model'].str.contains(model_name, na=False)] # 使用 current_train_log_df\n",
    "        if len(overall_model_df) > 0 and len(train_log_model_df) > 0:\n",
    "            best_metric_value = overall_model_df[best_metric_col].max()\n",
    "            best_metric_model = current_overall_df[current_overall_df[best_metric_col] == best_metric_value]['Model'].iloc[0] # 使用 current_overall_df\n",
    "            best_metric_subfolder = current_overall_df[current_overall_df[best_metric_col] == best_metric_value]['Subfolder'].iloc[0] # 使用 current_overall_df\n",
    "\n",
    "            best_metric_subfolder = str(best_metric_subfolder)\n",
    "\n",
    "            best_train_log_model_df = train_log_model_df[train_log_model_df['model'].str.contains(best_metric_model, na=False) & train_log_model_df['model'].str.contains(best_metric_subfolder, na=False)]\n",
    "            if len(best_train_log_model_df) > 0:\n",
    "                best_mAP = float(best_train_log_model_df['mAP'].str.split('_').str[0].iloc[0]) / 1000\n",
    "                print(f\"Best {metric_to_use} Model: {best_metric_model}, Subfolder: {best_metric_subfolder}, Best {metric_to_use}: {best_metric_value}, mAP: {best_mAP}\")\n",
    "\n",
    "                # 比较其他模型\n",
    "                for index, row in overall_model_df.iterrows(): # 循环 overall_model_df\n",
    "                    other_model_name = row['Model']\n",
    "                    other_subfolder_name = row['Subfolder']\n",
    "                    other_metric_value = row[best_metric_col]\n",
    "\n",
    "                    other_train_log_model_df = train_log_model_df[train_log_model_df['model'].str.contains(other_model_name, na=False) & train_log_model_df['model'].str.contains(str(other_subfolder_name), na=False)]\n",
    "                    if len(other_train_log_model_df) > 0:\n",
    "                        other_mAP = float(other_train_log_model_df['mAP'].str.split('_').str[0].iloc[0]) / 1000\n",
    "                        if other_metric_value < best_metric_value and other_mAP < best_mAP:\n",
    "                            print(f\"Found a worse model: {other_model_name}, Subfolder: {other_subfolder_name}, {metric_to_use}: {other_metric_value}, mAP: {other_mAP}\")\n",
    "                            models_to_delete.append((other_model_name, other_subfolder_name))\n",
    "\n",
    "    # 2. 处理多余的 Subfolder\n",
    "    for model_name in current_overall_df['Model'].unique(): # 循环 current_overall_df\n",
    "        model_df = current_overall_df[current_overall_df['Model'] == model_name].copy() # 使用 current_overall_df\n",
    "        model_df['Subfolder'] = pd.to_numeric(model_df['Subfolder'], errors='coerce')\n",
    "        model_df = model_df.sort_values(by=[best_metric_col, 'Subfolder'], ascending=[False, False])\n",
    "\n",
    "        # 2.1 移除 完全被上位的 Subfolder\n",
    "        for index, current_row in model_df.iterrows():\n",
    "            current_subfolder_name = str(current_row['Subfolder'])\n",
    "            current_metric_value = current_row[best_metric_col]\n",
    "            current_map = current_row['Subfolder']\n",
    "            is_dominated = False # 标记是否被上位\n",
    "\n",
    "            for other_index, other_row in model_df.iterrows():\n",
    "                if index == other_index: # 避免和自己比较\n",
    "                    continue\n",
    "\n",
    "                other_subfolder_name = str(other_row['Subfolder'])\n",
    "                other_metric_value = other_row[best_metric_col]\n",
    "                other_map = other_row['Subfolder']\n",
    "\n",
    "                if other_metric_value > current_metric_value and other_map > current_map: # 找到上位模型\n",
    "                    is_dominated = True\n",
    "                    print(f\"Subfolder {current_subfolder_name} is dominated by {other_subfolder_name}\")\n",
    "                    break # 只要找到一个上位模型就标记为删除\n",
    "\n",
    "            if is_dominated:\n",
    "                if (model_name, current_subfolder_name) not in models_to_delete:\n",
    "                    print(f\"Adding to delete list: {model_name}, {current_subfolder_name} (dominated)\")\n",
    "                    models_to_delete.append((model_name, current_subfolder_name))\n",
    "\n",
    "\n",
    "        # 2.2 检查是否超过 max_subfolders_to_keep，如果超过则删除 F1 较差的 (保持不变)\n",
    "        remaining_subfolders = model_df[~model_df.apply(lambda row: (row['Model'], str(row['Subfolder'])) in models_to_delete, axis=1)]\n",
    "        if len(remaining_subfolders) > max_subfolders_to_keep:\n",
    "            subfolders_to_delete_count = len(remaining_subfolders) - max_subfolders_to_keep\n",
    "            subfolders_to_delete_metric_sort = remaining_subfolders.sort_values(by=best_metric_col, ascending=True) # 按指标升序排\n",
    "            subfolders_to_delete_excess = subfolders_to_delete_metric_sort.iloc[:subfolders_to_delete_count] # 取前n个\n",
    "            for index, row in subfolders_to_delete_excess.iterrows():\n",
    "                subfolder_name = str(row['Subfolder'])\n",
    "                if (model_name, subfolder_name) not in models_to_delete:\n",
    "                    print(f\"Adding to delete list: {model_name}, {subfolder_name} (exceeds max_subfolders)\")\n",
    "                    models_to_delete.append((model_name, subfolder_name))\n",
    "\n",
    "    print(\"models_to_delete:\", models_to_delete) # 打印待删除列表\n",
    "\n",
    "    # 3. 执行删除操作\n",
    "    for model_name, subfolder_name in models_to_delete:\n",
    "        current_overall_df, current_train_log_df = delete_model_and_results(model_name, subfolder_name, current_overall_df, current_train_log_df, train_log_path, overall_results_path)\n",
    "\n",
    "\n",
    "    return current_overall_df, current_train_log_df # 返回更新后的 DataFrame\n",
    "\n",
    "\n",
    "def clean_exp_folders(runs_path, dataset_name, model_name, best_subfolder, metric_to_use): #添加 metric_to_use\n",
    "    \"\"\"\n",
    "    清理与最佳模型子文件夹在同一父目录下的无用exp*文件夹。\n",
    "    \"\"\"\n",
    "    model_path = os.path.join(runs_path, dataset_name, model_name)\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Warning: Model path not found: {model_path}\")\n",
    "        return\n",
    "\n",
    "    parent_dir = model_path  # 父目录是runs/dataset/model\n",
    "\n",
    "    # 遍历父目录下的所有文件夹\n",
    "    for item in os.listdir(parent_dir):\n",
    "        item_path = os.path.join(parent_dir, item)\n",
    "\n",
    "        # 检查是否为目录，并且名称以exp_prefix开头，且不是最佳子文件夹\n",
    "        if os.path.isdir(item_path) and item.startswith(exp_prefix) and item != str(best_subfolder):\n",
    "            try:\n",
    "                shutil.rmtree(item_path)\n",
    "                print(f\"Deleted extraneous exp folder: {item_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting folder: {item_path}. {e}\")\n",
    "\n",
    "# --- 主程序 ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 加载CSV文件\n",
    "    try:\n",
    "        overall_df = pd.read_csv(overall_results_path)\n",
    "        train_log_df = pd.read_csv(train_log_path)\n",
    "        best_metrics_df = pd.read_csv(best_metrics_path) # 加载best_patient_level_metrics.csv\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error loading CSV files: {e}\")\n",
    "        exit()\n",
    "\n",
    "    # 模型管理，获取待删除列表并执行删除\n",
    "    overall_df, train_log_df = manage_models(overall_df, train_log_df, train_log_path, overall_results_path, best_metrics_df, metric_to_use)\n",
    "\n",
    "    # 清理多余的exp文件夹\n",
    "    if metric_to_use == 'F1-Score':\n",
    "        best_metric_col = 'Best F1-Score'\n",
    "    elif metric_to_use == 'Weighted_metric':\n",
    "        best_metric_col = 'Weighted_metric'\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid metric: {metric_to_use}.  Must be one of {METRIC_CHOICES}\")\n",
    "\n",
    "    for model_name in overall_df['Model'].unique():\n",
    "        # 获取当前模型的所有记录\n",
    "        overall_model_df = overall_df[overall_df['Model'] == model_name]\n",
    "        if len(overall_model_df) > 0:\n",
    "            best_metric_value = overall_model_df[best_metric_col].max()\n",
    "            best_metric_subfolder = overall_df[overall_df[best_metric_col] == best_metric_value]['Subfolder'].iloc[0] # 获取最佳指标 subfolder名称\n",
    "            clean_exp_folders(runs_path, dataset_name, model_name, best_metric_subfolder, metric_to_use) #添加 metric_to_use\n",
    "\n",
    "    # 保存更新后的总表\n",
    "    overall_df.to_csv(overall_results_path, index=False)\n",
    "    train_log_df.to_csv(train_log_path, index=False)\n",
    "    print(f\"Updated overall_results.csv saved to {overall_results_path}\")\n",
    "    print(f\"Updated train_log.csv saved to {train_log_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"map_sort\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_sort\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "target_map = 660\n",
    "csv_file = \"./yolov12/results/thyroid_bm_b-mode/train_log.csv\"\n",
    "output_dir = \"./yolov12/results/\"\n",
    "    \n",
    "def split_dataframe_by_map(csv_file, target_map, output_dir):\n",
    "    \"\"\"\n",
    "    将包含模型名称和mAP值的CSV文件，根据指定的mAP值分割成两个文件。\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): CSV文件的路径。\n",
    "        target_map (float): 用于分割的mAP值。\n",
    "        output_dir (str): 输出文件所在的目录。\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误：文件未找到：{csv_file}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"读取CSV文件时发生错误：{e}\")\n",
    "        return\n",
    "\n",
    "    if 'model' not in df.columns or 'mAP' not in df.columns:\n",
    "        print(\"错误：CSV文件缺少 'model' 或 'mAP' 列。\")\n",
    "        return\n",
    "\n",
    "    # 从 'mAP_epoch' 列提取 mAP 值，并转换为浮点数\n",
    "    df['mAP_value'] = df['mAP'].astype(str).str.split('_').str[0].astype(float)\n",
    "\n",
    "    # 创建高于和低于目标mAP值的两个DataFrame\n",
    "    df_above = df[df['mAP_value'] >= target_map].copy()\n",
    "    df_below = df[df['mAP_value'] < target_map].copy()\n",
    "\n",
    "    # 按mAP值从高到低排序\n",
    "    df_above = df_above.sort_values(by='mAP_value', ascending=False)\n",
    "    df_below = df_below.sort_values(by='mAP_value', ascending=False)\n",
    "\n",
    "    # 删除临时 'map_value' 列\n",
    "    df_above = df_above.drop('mAP_value', axis=1)\n",
    "    df_below = df_below.drop('mAP_value', axis=1)\n",
    "\n",
    "    # 确保输出目录存在\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 构建输出文件名\n",
    "    base_filename = os.path.splitext(os.path.basename(csv_file))[0]  # 获取不带扩展名的文件名\n",
    "    above_filename = os.path.join(output_dir, f\"{base_filename}_above_{target_map}.csv\")\n",
    "    below_filename = os.path.join(output_dir, f\"{base_filename}_below_{target_map}.csv\")\n",
    "\n",
    "    # 保存DataFrame到CSV文件\n",
    "    try:\n",
    "        df_above.to_csv(above_filename, index=False)\n",
    "        df_below.to_csv(below_filename, index=False)\n",
    "        print(f\"已将高于 {target_map} mAP 的数据保存到：{above_filename}\")\n",
    "        print(f\"已将低于 {target_map} mAP 的数据保存到：{below_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"保存CSV文件时发生错误：{e}\")\n",
    "\n",
    "split_dataframe_by_map(csv_file, target_map, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"config_test_examination\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_test_examination\n",
    "import pandas as pd\n",
    "\n",
    "# 定义路径\n",
    "test_train_path = \"./yolov12/configs/test_train.csv\"\n",
    "train_log_path = \"./yolov12/results/test/train_log.csv\"\n",
    "\n",
    "\n",
    "def standardize_model_name(model_name):\n",
    "    \"\"\"将模型名称标准化为 yolo11{model_name}.yaml 格式\"\"\"\n",
    "    if not isinstance(model_name, str):\n",
    "        return None  # 或者抛出异常，取决于你如何处理非字符串输入\n",
    "\n",
    "    # 移除所有前缀和后缀\n",
    "    cleaned_name = model_name.replace(\"yolo11\", \"\").replace(\"11n\", \"\").replace(\".yaml\", \"\")\n",
    "\n",
    "    # 确保清理后的名称不为空\n",
    "    if not cleaned_name:\n",
    "        return None\n",
    "\n",
    "    return f\"yolo11{cleaned_name}.yaml\"\n",
    "\n",
    "\n",
    "def get_standardized_model_names(csv_path):\n",
    "    \"\"\"从CSV文件中读取模型名称，并标准化格式\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # 确保 'model' 列存在\n",
    "        if 'model' not in df.columns:\n",
    "            print(f\"Error: 'model' column not found in {csv_path}\")\n",
    "            return set()\n",
    "\n",
    "        model_names = df['model'].dropna().tolist()  # 移除 NaN 值\n",
    "\n",
    "        # 标准化模型名称并转换为集合\n",
    "        standardized_model_names = {\n",
    "            standardize_model_name(name)\n",
    "            for name in model_names\n",
    "            if isinstance(name, str) and standardize_model_name(name) is not None\n",
    "        }\n",
    "\n",
    "        return standardized_model_names\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {csv_path}\")\n",
    "        return set()\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Error: CSV file is empty: {csv_path}\")\n",
    "        return set()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading {csv_path}: {e}\")\n",
    "        return set()\n",
    "\n",
    "\n",
    "# 获取模型名称集合\n",
    "test_train_models = get_standardized_model_names(test_train_path)\n",
    "train_log_models = get_standardized_model_names(train_log_path)\n",
    "\n",
    "# 找出 test_train.csv 中有，但 train_log.csv 中没有的模型\n",
    "models_only_in_test_train = test_train_models - train_log_models\n",
    "\n",
    "# 找出 train_log.csv 中有，但 test_train.csv 中没有的模型\n",
    "models_only_in_train_log = train_log_models - test_train_models\n",
    "\n",
    "\n",
    "# 打印结果\n",
    "print(\"Models in test_train.csv but not in train_log.csv:\")\n",
    "for model in models_only_in_test_train:\n",
    "    print(model)\n",
    "\n",
    "print(\"\\nModels in train_log.csv but not in test_train.csv:\")\n",
    "for model in models_only_in_train_log:\n",
    "    print(model)\n",
    "\n",
    "\n",
    "def check_duplicates(csv_path):\n",
    "    \"\"\"检查指定CSV文件中'model'列是否有重复值，并打印结果。\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        # 确保 'model' 列存在\n",
    "        if 'model' not in df.columns:\n",
    "            print(f\"Error: 'model' column not found in {csv_path}\")\n",
    "            return\n",
    "\n",
    "        model_counts = df['model'].value_counts()\n",
    "        duplicate_models = model_counts[model_counts > 1]\n",
    "\n",
    "        if not duplicate_models.empty:\n",
    "            print(f\"\\nDuplicate models found in {csv_path}:\")\n",
    "            print(duplicate_models)\n",
    "        else:\n",
    "            print(f\"\\nNo duplicate models found in {csv_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {csv_path}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Error: CSV file is empty: {csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading {csv_path}: {e}\")\n",
    "\n",
    "\n",
    "# 检查 train_log.csv 中是否有重复训练的记录\n",
    "print(\"\\nChecking train_log.csv for duplicates...\")\n",
    "check_duplicates(train_log_path)\n",
    "\n",
    "# 检查 test_train.csv 中是否有重复的模型\n",
    "print(\"\\nChecking test_train.csv for duplicates...\")\n",
    "check_duplicates(test_train_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}